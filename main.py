# -*- coding: utf-8 -*-
"""
Tving ë³‘ë ¬ í¬ë¡¤ë§ ë° ë°ì´í„° ë³‘í•©/ì²˜ë¦¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""
import sys
import pandas as pd
import glob
import os
from concurrent.futures import ThreadPoolExecutor
from config import genre_links
from crawler import crawl_tving_category

# Windows í„°ë¯¸ë„ì˜ ì¸ì½”ë”© ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ í‘œì¤€ ì¶œë ¥ ì¸ì½”ë”©ì„ UTF-8ë¡œ ì„¤ì •
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8')

def merge_and_process_data():
    """
    í¬ë¡¤ë§ëœ CSV íŒŒì¼ë“¤ì„ ë³‘í•©í•˜ê³  ì¤‘ë³µ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        sub_dirs = ['ë“œë¼ë§ˆ', 'ì• ë‹ˆ', 'ì˜í™”', 'ì˜ˆëŠ¥']
        all_files = []
        for sub_dir in sub_dirs:
            path = os.path.join(base_dir, sub_dir, '*.csv')
            found_files = glob.glob(path)
            all_files.extend(found_files)

        if not all_files:
            print("ë³‘í•©í•  CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"ì´ {len(all_files)}ê°œì˜ íŒŒì¼ì„ ë³‘í•©í•˜ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        all_dfs = []
        for f in all_files:
            try:
                df = pd.read_csv(f)
                all_dfs.append(df)
            except Exception as e:
                print(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {f}, ì˜¤ë¥˜: {e}")

        if not all_dfs:
            print("ë³‘í•©í•  ë°ì´í„°í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        merged_df = pd.concat(all_dfs, ignore_index=True)

        key_cols = ['title', 'genre', 'description']
        for col in key_cols:
            if col in merged_df.columns:
                merged_df[col] = merged_df[col].fillna('')

        if 'subgenre' in merged_df.columns:
            merged_df['subgenre'] = merged_df['subgenre'].astype(str).replace('nan', '')

        agg_funcs = {col: 'first' for col in merged_df.columns if col not in ['title', 'genre', 'description', 'subgenre']}
        agg_funcs['subgenre'] = lambda x: ','.join(sorted(set(i for i in x if i)))

        processed_df = merged_df.groupby(key_cols, as_index=False).agg(agg_funcs)
        
        processed_df = processed_df[merged_df.columns.tolist()]

        output_file = os.path.join(base_dir, 'tving_final_merged_data.csv')
        processed_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        print(f"âœ… ì„±ê³µì ìœ¼ë¡œ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ {output_file} ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        print(f"   - ì›ë³¸ ë°ì´í„° ìˆ˜: {len(merged_df)}")
        print(f"   - ì¤‘ë³µ ì²˜ë¦¬ í›„ ë°ì´í„° ìˆ˜: {len(processed_df)}")

    except Exception as e:
        print(f"ë°ì´í„° ë³‘í•© ë° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    # 1. ë³‘ë ¬ í¬ë¡¤ë§ ì‹¤í–‰
    print("ğŸš€ Tving ë³‘ë ¬ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(crawl_tving_category, genre, subgenre, url) for genre, subgenre, url in genre_links]
        
        for future in futures:
            future.result()

    print("ğŸ‰ ì „ì²´ ë³‘ë ¬ í¬ë¡¤ë§ ì™„ë£Œ!")
    
    # 2. ë°ì´í„° ë³‘í•© ë° ì²˜ë¦¬ ì‹¤í–‰
    print("\nğŸ”„ í¬ë¡¤ë§ëœ ë°ì´í„°ì˜ ë³‘í•© ë° ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    merge_and_process_data()
    print("\nâœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
